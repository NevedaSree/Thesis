{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001D9418767F0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D90055BE10> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D90030EB00> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D901B727F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D901B7B4A8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D90070F320> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D9007280F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D900728A20> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D90075B080> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D9007797F0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D9007950F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D900795A20> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D9007C9080> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D9007E77F0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D9008020F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D900802A20> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D900837080> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D9008537F0> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D90086F0F0> True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 16,816,964\n",
      "Trainable params: 16,816,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 250 images belonging to 4 classes.\n",
      "Found 240 images belonging to 4 classes.\n",
      "Epoch 1/50\n",
      "8/7 [==============================] - 48s 6s/step - loss: 7.1196 - acc: 0.3424 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 2/50\n",
      "8/7 [==============================] - 45s 6s/step - loss: 9.6760 - acc: 0.3997 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 3/50\n",
      "8/7 [==============================] - 42s 5s/step - loss: 9.6502 - acc: 0.4013 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 4/50\n",
      "8/7 [==============================] - 41s 5s/step - loss: 9.6373 - acc: 0.4021 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 5/50\n",
      "8/7 [==============================] - 42s 5s/step - loss: 9.7019 - acc: 0.3981 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "8/7 [==============================] - 43s 5s/step - loss: 9.7148 - acc: 0.3973 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 7/50\n",
      "8/7 [==============================] - 40s 5s/step - loss: 9.7148 - acc: 0.3973 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 8/50\n",
      "8/7 [==============================] - 40s 5s/step - loss: 9.6114 - acc: 0.4037 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 9/50\n",
      "8/7 [==============================] - 44s 5s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 10/50\n",
      "8/7 [==============================] - 44s 6s/step - loss: 9.7019 - acc: 0.3981 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 11/50\n",
      "8/7 [==============================] - 43s 5s/step - loss: 9.5856 - acc: 0.4053 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 12/50\n",
      "8/7 [==============================] - 44s 6s/step - loss: 9.6373 - acc: 0.4021 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 13/50\n",
      "8/7 [==============================] - 44s 6s/step - loss: 9.6631 - acc: 0.4005 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 14/50\n",
      "8/7 [==============================] - 44s 5s/step - loss: 9.6244 - acc: 0.4029 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 15/50\n",
      "8/7 [==============================] - 38s 5s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 16/50\n",
      "8/7 [==============================] - 40s 5s/step - loss: 9.6114 - acc: 0.4037 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 17/50\n",
      "8/7 [==============================] - 39s 5s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 18/50\n",
      "8/7 [==============================] - 43s 5s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 19/50\n",
      "8/7 [==============================] - 44s 5s/step - loss: 9.6631 - acc: 0.4005 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 20/50\n",
      "8/7 [==============================] - 44s 6s/step - loss: 9.6244 - acc: 0.4029 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 21/50\n",
      "8/7 [==============================] - 43s 5s/step - loss: 9.6502 - acc: 0.4013 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 22/50\n",
      "8/7 [==============================] - 42s 5s/step - loss: 9.7019 - acc: 0.3981 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 23/50\n",
      "8/7 [==============================] - 40s 5s/step - loss: 9.7019 - acc: 0.3981 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 24/50\n",
      "8/7 [==============================] - 41s 5s/step - loss: 9.6114 - acc: 0.4037 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 25/50\n",
      "8/7 [==============================] - 44s 5s/step - loss: 9.6760 - acc: 0.3997 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 26/50\n",
      "8/7 [==============================] - 46s 6s/step - loss: 9.7277 - acc: 0.3965 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 27/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.6373 - acc: 0.4021 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 28/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 29/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.7019 - acc: 0.3981 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 30/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.6889 - acc: 0.3989 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 31/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.6760 - acc: 0.3997 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 32/50\n",
      "8/7 [==============================] - 50s 6s/step - loss: 9.6502 - acc: 0.4013 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 33/50\n",
      "8/7 [==============================] - 47s 6s/step - loss: 9.6760 - acc: 0.3997 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 34/50\n",
      "8/7 [==============================] - 44s 5s/step - loss: 9.6244 - acc: 0.4029 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 35/50\n",
      "8/7 [==============================] - 47s 6s/step - loss: 9.6502 - acc: 0.4013 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 36/50\n",
      "8/7 [==============================] - 47s 6s/step - loss: 9.6760 - acc: 0.3997 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 37/50\n",
      "8/7 [==============================] - 47s 6s/step - loss: 9.6244 - acc: 0.4029 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 38/50\n",
      "8/7 [==============================] - 20716s 2590s/step - loss: 9.6373 - acc: 0.4021 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 39/50\n",
      "2/7 [======>.......................] - ETA: 31s - loss: 7.8072 - acc: 0.5156"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "#Load the VGG model\n",
    "vgg_conv = VGG16(weights=None, include_top=False, input_shape= (64, 64, 3))\n",
    "\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in vgg_conv.layers[:-4]:\n",
    "#layer.trainable = False\n",
    " \n",
    " # Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "    \n",
    "model = models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    " \n",
    "# Add new layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'C:/Users/neved/Desktop/spectrogram/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'C:/Users/neved/Desktop/spectrogram/validation',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
